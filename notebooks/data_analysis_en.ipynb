{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b496d48f",
   "metadata": {},
   "source": [
    "# <h1 style=\"text-align:center;\">**First Data Analysis:**</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f78e57",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716d77b5",
   "metadata": {},
   "source": [
    "### **Project Presentation**\n",
    "\n",
    "This Jupyter notebook defines the methodology for **ingestion**, **processing**, and **enrichment** of data for the ANSSI alert project. The objective is to consolidate disparate sources (RSS feeds, threat metrics, and weakness repositories) into a single, actionable data structure for our cybersecurity application.\n",
    "\n",
    "### **Methodological Approach**\n",
    "\n",
    "The workflow is broken down into three critical phases:\n",
    "\n",
    "1. **Initial Collection and Transformation**:\n",
    "* Retrieval of security bulletins via the **ANSSI RSS feed**.\n",
    "* Structuring raw data into a first **Pandas** DataFrame.\n",
    "\n",
    "\n",
    "2. **API Enrichment (Threat Vector)**:\n",
    "* Extraction of **CVE** (Common Vulnerabilities and Exposures) identifiers.\n",
    "* API calls to integrate **EPSS** (Exploit Prediction Scoring System) scores, measuring the real probability of vulnerability exploitation.\n",
    "\n",
    "\n",
    "3. **Business Consolidation (MITRE Repository)**:\n",
    "* Querying the **MITRE API** to retrieve contextual metadata (descriptions, CWE weakness types).\n",
    "* Creation of a second normalized DataFrame based on the `CVE` primary key.\n",
    "\n",
    "\n",
    "\n",
    "### **Expected Result**\n",
    "\n",
    "The process concludes with the **merging** of the two datasets. We obtain a final enriched DataFrame, offering a 360Â° view of each alert: from its official publication to its technical severity score, thus constituting the data engine of our application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f970272a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d51d2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser # To retrieve data from an RSS feed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import requests # To make API requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfed3a13",
   "metadata": {},
   "source": [
    "# **I - ANSSI Data Retrieval:**\n",
    "ANSSI writes alerts and advisories on security vulnerabilities. Thus, we retrieve the RSS feed in the form of a parsefeeddict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2090ffe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "anssi_feed = feedparser.parse(\"https://www.cert.ssi.gouv.fr/feed/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdda23b",
   "metadata": {},
   "source": [
    "The data is in list form under the \"entries\" key. Let's take the time to look at how the data is presented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1226b1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if anssi_feed.entries:\n",
    "    for k,v in anssi_feed.entries[1].items():\n",
    "        print(f\"[{k} | {type(v)}] -> {v}\", end = \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5120653a",
   "metadata": {},
   "source": [
    "To summarize, the RSS feed returns:\n",
    "| Element | Type | Description |\n",
    "| --- | --- | --- |\n",
    "| **`title`** | `str` | The title of the alert. Here, it contains the product name and the initial publication date. |\n",
    "| **`title_detail`** | `dict` | Contains metadata about the title: its format (`text/plain`), language, and source URL (`base`). |\n",
    "| **`links`** | `list` | A list of dictionaries containing associated links. It often contains the link to the official HTML page. |\n",
    "| **`link`** | `str` | The direct URL to the alert on the CERT-FR site (shortcut of the first link in `links`). |\n",
    "| **`summary`** | `str` | A text summary (often with HTML). |\n",
    "| **`summary_detail`** | `dict` | Technical details of the summary. |\n",
    "| **`id`** | `str` | The unique identifier of the entry (often identical to the URL). |\n",
    "| **`guidislink`** | `bool` | Indicates if the identifier (`id`) is a usable URL link. |\n",
    "| **`published`** | `str` | The publication date in text format. |\n",
    "| **`published_parsed`** | `struct` | The date converted into a `time.struct_time` object, allowing for easy sorting of CVEs by year or month. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e250f8a",
   "metadata": {},
   "source": [
    "Some data is useless to us. For example: `summary`, `isguidislink`, `id`, and `links` do not interest us. In the case of `title_detail` and `summary_detail`, we will reformat the data structure to keep only what is relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bc9ee62",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(anssi_feed.entries)):\n",
    "    # Some data is stored in sub-lists or sub-dictionaries, we retrieve only part of this data\n",
    "    if \"title_detail\" in anssi_feed.entries[i] and type(anssi_feed.entries[i][\"title_detail\"]) == feedparser.util.FeedParserDict:\n",
    "        anssi_feed.entries[i][\"title\"] = anssi_feed.entries[i][\"title_detail\"][\"value\"]\n",
    "\n",
    "    if \"summary_detail\" in anssi_feed.entries[i] and type(anssi_feed.entries[i][\"summary_detail\"]) == feedparser.util.FeedParserDict:\n",
    "        anssi_feed.entries[i][\"summary_detail\"] = anssi_feed.entries[i][\"summary_detail\"][\"value\"]\n",
    "\n",
    "    if \"published_parsed\" in anssi_feed.entries[i]:\n",
    "        anssi_feed.entries[i][\"published\"] = pd.to_datetime(datetime.datetime.fromtimestamp(time.mktime(anssi_feed.entries[i][\"published_parsed\"]))) # Transformation of the date to datetime format\n",
    "        del anssi_feed.entries[i][\"published_parsed\"] # We prefer to keep only the date in datetime type and keep published as the key name\n",
    "\n",
    "    # We remove what we don't need:\n",
    "    if \"summary\" in anssi_feed.entries[i]:\n",
    "        del anssi_feed.entries[i][\"summary\"]\n",
    "    if \"id\" in anssi_feed.entries[i]:\n",
    "        del anssi_feed.entries[i][\"id\"]\n",
    "    if \"guidislink\" in anssi_feed.entries[i]:\n",
    "        del anssi_feed.entries[i][\"guidislink\"]\n",
    "    if \"title_detail\" in anssi_feed.entries[i]:\n",
    "        del anssi_feed.entries[i][\"title_detail\"]\n",
    "    if \"links\" in anssi_feed.entries[i]:\n",
    "        del anssi_feed.entries[i][\"links\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e162778e",
   "metadata": {},
   "source": [
    "We can now pass this data into a dataframe which we sort by publication date (from most recent to oldest). The most recent is the largest index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d1dad50",
   "metadata": {},
   "outputs": [],
   "source": [
    "anssi_df = pd.DataFrame.from_dict(anssi_feed.entries)\n",
    "anssi_df.sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68212d11",
   "metadata": {},
   "source": [
    "There are two types of ANSSI publications, alerts and advisories. Let's create a column that categorizes the publications based on the link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d4c06b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\n",
    "    anssi_df[\"link\"].str.contains(\"alerte\", case=False, na=False),\n",
    "    anssi_df[\"link\"].str.contains(\"avis\", case=False, na=False)\n",
    "]\n",
    "anssi_df[\"type_publication\"] = np.select(conditions, [\"alerte\", \"avis\"], default=None)\n",
    "\n",
    "anssi_df = anssi_df.dropna(subset=[\"type_publication\"]) # We remove everything that is neither an advisory nor an alert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b2f7a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "anssi_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aac0be9",
   "metadata": {},
   "source": [
    "# **II - Retrieval of the CVE (Common Vulnerabilities and Exposures):**\n",
    "\n",
    "The CVE is a unique key that identifies a vulnerability. The ANSSI feed does not directly provide this identifier, which is why we will scrape the page of each alert/advisory to get the CVEs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "809040f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = requests.Session() # Creating a session helps reduce execution time during many requests\n",
    "\n",
    "def get_cve(anssi_url): # The function was optimized with Gemini Pro\n",
    "    if not isinstance(anssi_url, str) or not anssi_url.strip(): # Ensuring the validity of the input argument\n",
    "        return []\n",
    "\n",
    "    target_url = anssi_url.rstrip(\"/\") + \"/json/\" # Retrieving the json of the page\n",
    "    \n",
    "    try:\n",
    "        # Using the global session\n",
    "        response = session.get(target_url, timeout=5) \n",
    "        \n",
    "        if response.status_code == 200: # If the request succeeds\n",
    "            # Method 1: using REGEX\n",
    "            # return list(set(re.findall(r\"CVE-\\d{4}-\\d{4,7}\", response.text)) )# set() for deduplication, list() for the final format\n",
    "        \n",
    "            # Method 2: Going through the cves key:\n",
    "            return [ v[\"name\"] for v in response.json()[\"cves\"] ]\n",
    "            \n",
    "    except requests.RequestException: # In case of network error (timeout, 404...), we return an empty list\n",
    "        print(\"Nothing was found on \", anssi_url)\n",
    "        return []\n",
    "    \n",
    "    return []\n",
    "\n",
    "print(anssi_df[\"link\"][0]) # Example link\n",
    "print(get_cve(anssi_df[\"link\"][0])) # Testing the function for an ANSSI alert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2a19bb",
   "metadata": {},
   "source": [
    "We just have to apply this function to the entire dataframe to create a CVE column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "357caa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "anssi_df[\"cve\"] = anssi_df[\"link\"].transform(get_cve) # Returns the list of CVEs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4a5bf0",
   "metadata": {},
   "source": [
    "But some publications do not have a CVE. This happens because sometimes ANSSI publishes recommendations on practices or to be vigilant about certain things. Thus, there is no referenced vulnerability with a CVE. This does not mean we should delete them from our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98c584d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "anssi_df[anssi_df[\"cve\"].str.len() == 0] # Rows without CVE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98bb299",
   "metadata": {},
   "source": [
    "It often happens that an ANSSI alert/advisory refers to several CVEs, but in the end, we want a Dataframe that gives information for each CVE vulnerability and not each ANSSI alert/advisory.\n",
    "That is why we will unpack these CVEs so that each CVE has its own row. Thus, one ANSSI alert can be associated with several CVEs.\n",
    "To do this, we use the `explode` method of dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cc0a4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "anssi_df = anssi_df.explode(\"cve\")\n",
    "anssi_df = anssi_df.reset_index(drop=True) # We reset the index because explode \"duplicates\" the indices. The drop argument removes the old index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8492d2",
   "metadata": {},
   "source": [
    "Here are the first 5 elements of the ANSSI alert dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c28319e",
   "metadata": {},
   "outputs": [],
   "source": [
    "anssi_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e03da8",
   "metadata": {},
   "source": [
    "# **III - Enrichment of the ANSSI dataframe with the EPSS score using the EPSS API:**\n",
    "The EPSS score represents the probability that a vulnerability will be exploited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0492b006",
   "metadata": {},
   "outputs": [],
   "source": [
    "epss_api_url = \"https://api.first.org/data/v1/epss?cve=\" \n",
    "\n",
    "def get_epss_data(cve): \n",
    "    target_url = epss_api_url + cve\n",
    "    \n",
    "    try:\n",
    "        res = session.get(target_url, timeout=5)\n",
    "\n",
    "        if res.status_code != 200:\n",
    "            print(res.status_code)\n",
    "            return {}\n",
    "\n",
    "        data = res.json()\n",
    "        \n",
    "        epss_data = data.get(\"data\", [])\n",
    "\n",
    "        if epss_data != []:\n",
    "            return float(epss_data[0][\"epss\"]) or np.nan\n",
    "\n",
    "        return np.nan\n",
    "    except Exception:\n",
    "        print(\"Nothing was found for \", cve)\n",
    "        return np.nan\n",
    "\n",
    "print(anssi_df[\"cve\"][0]) # A CVE identifier\n",
    "print(get_epss_data(anssi_df[\"cve\"][0])) # Testing the function for 1 CVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ade25e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "anssi_df[\"epss_score\"] = anssi_df[\"cve\"].transform(lambda x: get_epss_data(x) if (pd.notna(x)) else np.nan) # We apply the function only if the CVE is not null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "404c4841",
   "metadata": {},
   "outputs": [],
   "source": [
    "anssi_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3dd67f",
   "metadata": {},
   "source": [
    "# **IV - Retrieval of MITRE Data:**\n",
    "We will create a second dataframe containing all the data provided by the MITRE API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f428731c",
   "metadata": {},
   "source": [
    "By looking closer at how the MITRE system and its [API](https://cveawg.mitre.org/api-docs/) work, we discovered that there are 3 states for a CVE:\n",
    "| State | Definition |\n",
    "| :--- | :--- |\n",
    "| **`RESERVED`** | A CVE number has been assigned to an organization (a vendor or a researcher), but the details of the vulnerability are not yet public. |\n",
    "| **`PUBLISHED`** | The vulnerability is official, technical details are available, and the analysis process is complete (or in progress). |\n",
    "| **`REJECTED`** | The CVE has been cancelled. This happens if the vulnerability was a duplicate of another, if it was a reporting error, or if the vulnerability turned out not to be one. |\n",
    "\n",
    "The MITRE API `https://cveawg.mitre.org/api/cve/{CVE}` returns the state of the CVE if the CVE is not reserved. If it is reserved, the call returns a 404 error (Page not found).\n",
    "\n",
    "It is possible to verify the state of the CVE upon a 404 response with `https://cveawg.mitre.org/api/cve-id/{CVE}`. \n",
    "However, we will not make these calls for performance reasons and because we are already certain we can filter out rejected and reserved CVEs.\n",
    "We remove all those rejected because they are no longer relevant and all those reserved because we have no information on the vulnerability, so nothing to report to our end user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ba2410f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mitre_api_url = \"https://cveawg.mitre.org/api/cve/\"\n",
    "\n",
    "def get_mitre_data(cve):\n",
    "    if pd.isna(cve):\n",
    "        return {}\n",
    "    \n",
    "    target_url = mitre_api_url + cve\n",
    "    \n",
    "    try:\n",
    "        res = session.get(target_url, timeout=5)\n",
    "        if res.status_code != 200:\n",
    "            print(f\"[ERROR-{res.status_code}] {cve}\")\n",
    "\n",
    "            return {}\n",
    "\n",
    "        data = res.json()\n",
    "\n",
    "        # We verify the state of the CVE\n",
    "        cveMetadata = data.get(\"cveMetadata\", {})\n",
    "        if cveMetadata != {}:\n",
    "            if cveMetadata[\"state\"] != \"PUBLISHED\": # If it is not published, we ignore it\n",
    "                return {}\n",
    "\n",
    "        cna = data.get(\"containers\", {}).get(\"cna\", {})\n",
    "        \n",
    "        # Secure extraction of the description\n",
    "        descriptions = cna.get(\"descriptions\", [])\n",
    "        desc = descriptions[0].get(\"value\", None) if descriptions else None\n",
    "\n",
    "        # Secure extraction of the CWE\n",
    "        problem_types = cna.get(\"problemTypes\", [])\n",
    "        cwe_id = np.nan\n",
    "        cwe_desc = np.nan\n",
    "        \n",
    "        if problem_types:\n",
    "            # We often take the first listed problem type\n",
    "            desc_list = problem_types[0].get(\"descriptions\", [])\n",
    "            if desc_list:\n",
    "                cwe_id = desc_list[0].get(\"cweId\", np.nan)\n",
    "                cwe_desc = desc_list[0].get(\"description\", np.nan)\n",
    "\n",
    "        metrics = cna.get(\"metrics\", [])\n",
    "        cvss_score = None\n",
    "        if metrics != []:\n",
    "            metrics = metrics[0]\n",
    "            for k in metrics.keys():\n",
    "                if \"cvss\" in k.lower():\n",
    "                    cvss_score = float(metrics[k][\"baseScore\"])\n",
    "                    break\n",
    "\n",
    "        # Construction of the final dictionary\n",
    "        return {\n",
    "            \"cve\": cve,\n",
    "            \"cwe\": cwe_id,\n",
    "            \"cwe_desc\": cwe_desc,\n",
    "            \"cvss_score\": cvss_score,\n",
    "            \"mitre_desc\": desc,\n",
    "            \"affected_product\": [ # By list comprehension method\n",
    "                {\n",
    "                    \"vendor\": prod.get(\"vendor\"),\n",
    "                    \"product\": prod.get(\"product\"),\n",
    "                    \"versions\": [v.get(\"version\") for v in prod.get(\"versions\", []) if v.get(\"status\") == \"affected\"]\n",
    "                }\n",
    "                for prod in cna.get(\"affected\", [])\n",
    "            ]\n",
    "        }\n",
    "    except Exception:\n",
    "        return {}\n",
    "\n",
    "print(anssi_df[\"cve\"][3])\n",
    "print(get_mitre_data(anssi_df[\"cve\"][3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4a23967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Singlethread version\n",
    "# mitre_data = [ get_mitre_data(cve) for cve in anssi_df[\"cve\"] ] # This execution takes time because it makes requests for each row of the df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "017a0072",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is multithreading which we won't keep in the final version of the notebook because it's not the place for it.\n",
    "\"\"\"\n",
    "\n",
    "# Multithread version\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm # To see the progress bar\n",
    "\n",
    "# 1. We retrieve the list of unique CVEs to avoid unnecessary calls\n",
    "liste_cves = anssi_df['cve'].unique().tolist()\n",
    "\n",
    "# 2. Configuration of the number of threads (ex: 10 to 20)\n",
    "# Too many threads can cause API blocking (Rate Limiting)\n",
    "MAX_WORKERS = 15 \n",
    "\n",
    "print(f\"Retrieving {len(liste_cves)} CVEs in progress...\")\n",
    "\n",
    "# 3. Parallel execution\n",
    "with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "    # We use tqdm to follow progress\n",
    "    mitre_data = list(tqdm(executor.map(get_mitre_data, liste_cves), total=len(liste_cves)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9bea63d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mitre_df = pd.DataFrame(mitre_data) # We transform our data into a df \n",
    "mitre_df = mitre_df.dropna(subset=['cve']) # This line removes rejected and reserved CVEs\n",
    "mitre_df = mitre_df.reset_index(drop=True)\n",
    "\n",
    "mitre_df.head() # We display the first 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae075723",
   "metadata": {},
   "source": [
    "By proceeding in this way, only published CVEs that represent a real threat remain in our df. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ce1d2d",
   "metadata": {},
   "source": [
    "# **V - Creation of the alert database:**\n",
    "We now have all the information to create the final DataFrame with all the information necessary for our application. Here is the structure of the dataframe we want:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6dc1fd",
   "metadata": {},
   "source": [
    "| Column Name | Definition & Details |\n",
    "| :--- | :--- |\n",
    "| **`anssi_title`** | Title of the ANSSI alert/advisory |\n",
    "| **`anssi_link`** | Link to the ANSSI alert/advisory |\n",
    "| **`anssi_desc`** | Description of the ANSSI alert/advisory |\n",
    "| **`anssi_published`** | Publication date of the ANSSI alert/advisory |\n",
    "| **`cve`** | Unique identifier of the table, unique number referring to the vulnerability |\n",
    "| **`epss_score`** | EPSS Score, Probability that the vulnerability is exploited |\n",
    "| **`cwe`** | The CWE (Common Weakness Enumeration) is a universal classification system that lists security weaknesses in software and hardware. |\n",
    "| **`cwe_desc`** | CWE Description |\n",
    "| **`cvss_score`** | CVSS Score, severity of the vulnerability |\n",
    "| **`mitre_desc`** | Description returned by the Mitre API |\n",
    "| **`affected_product`** | List of affected products table with vendor name, affected product, and vulnerable versions |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4636d611",
   "metadata": {},
   "source": [
    "We will create this dataframe by merging mitre_df and anssi_df on the CVE column values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8c6b48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "anssi_df.columns = ['anssi_title', 'anssi_link', 'anssi_desc', 'anssi_published', 'type_publication', 'cve', 'epss_score'] # Renaming column names\n",
    "\n",
    "DB = anssi_df.merge(mitre_df, on='cve', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "063881c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_severity(cvss_score):\n",
    "    if pd.isna(cvss_score):\n",
    "        return np.nan\n",
    "    \n",
    "    if cvss_score >= 9:\n",
    "        return \"Critical\"\n",
    "    elif cvss_score >= 7:\n",
    "        return \"High\"\n",
    "    elif cvss_score >= 4:\n",
    "        return \"Medium\"\n",
    "    else:\n",
    "        return \"Low\"\n",
    "\n",
    "DB[\"base_severity\"] = DB[\"cvss_score\"].transform(set_severity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4fe6ef9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b25c9c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f1a6d1",
   "metadata": {},
   "source": [
    "# **VI - Interpretation, analysis, and visualization of data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "532f984a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65a247d",
   "metadata": {},
   "source": [
    "## 1) Histogram of vulnerability severity:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b143ce",
   "metadata": {},
   "source": [
    "### *a. Result Formatting:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd743305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for plots remains same but comments would be translated\n",
    "plt.title(\"Vulnerability Severity Distribution\", fontsize=16, pad=20, fontweight='bold')\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"Occurrence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c49fa1",
   "metadata": {},
   "source": [
    "### *c. Interpretation:*\n",
    "We noted three observations:\n",
    "\n",
    "- **Patching Priority**: Remediation efforts must focus on Red Hat / Linux, which not only suffers the most bulletins but also the most technically varied vulnerabilities.\n",
    "\n",
    "- **Risk Vector #1**: Availability (DoS via resources) is the most frequent risk, but Memory Corruption is the deepest risk (often allowing remote code execution).\n",
    "\n",
    "- **Data Observation**: It is interesting to note that the correlation matrix displays figures (e.g., 75 for Red Hat/CWE-22) much higher than the global occurrences graph. This suggests that a single bulletin can contain many CVEs, thus multiplying the actual impact per vulnerability type."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
